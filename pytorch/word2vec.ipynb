{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4203c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6701e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return(log_probs)\n",
    "    \n",
    "#\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_word_vec(word,word_to_ix,device=\"cpu\"):\n",
    "    context_ids = make_context_vector(word, word_to_ix).to(device)\n",
    "    assert context_ids.is_cuda is True # returns a boolean\n",
    "    return model.embeddings(context_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb91d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: {'of', 'spells.', 'process.', 'direct', 'beings', 'evolve,', 'We', 'inhabit', 'the', 'processes.', 'our', 'processes', 'directed', 'idea', 'computational', 'As', 'rules', 'study', 'is', 'spirits', 'they', 'things', 'People', 'by', 'other', 'data.', 'manipulate', 'evolution', 'with', 'Computational', 'are', 'computers.', 'pattern', 'that', 'to', 'The', 'effect,', 'computer', 'a', 'programs', 'we', 'In', 'called', 'abstract', 'process', 'conjure', 'program.', 'about', 'create'}\n",
      "data:[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n",
      "make_context_vector: tensor([ 6, 30, 34, 17])\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"vocab: {vocab}\")\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(f\"data:{data[:5]}\")\n",
    "\n",
    "#\n",
    "\n",
    "print(f\"make_context_vector: {make_context_vector(data[0][0], word_to_ix)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6054d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "device = torch.device('cuda:0')\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), embedding_dim=10, context_size=CONTEXT_SIZE*2)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ebbbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2045,  1.0123, -0.2335, -1.1488,  1.3003,  0.2334,  1.1850,  0.7958,\n",
       "          0.4326,  0.1962]], device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_vec([data[0][0][0]],word_to_ix,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1c06c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([241.7639]), tensor([146.7071]), tensor([55.8986]), tensor([11.7638]), tensor([3.5352]), tensor([1.4778]), tensor([1.1253]), tensor([0.9112]), tensor([0.7662]), tensor([0.6610])]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in data:\n",
    "        context_ids = make_context_vector(context, word_to_ix)\n",
    "        context_ids = context_ids.to(device)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_ids)\n",
    "        label = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        label = label.to(device)\n",
    "        loss = loss_function(log_probs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b7da9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2357,  1.0574, -0.2192, -1.1787,  1.3493,  0.2485,  1.2024,  0.7948,\n",
       "          0.4299,  0.1936]], device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_vec([data[0][0][0]],word_to_ix,device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926c1f6",
   "metadata": {},
   "source": [
    "## 中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f183a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /home/gavin/.local/lib/python3.8/site-packages (0.42.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0aa5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.353 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab: {'（', '1145', '中央', '今天上午', '表示', '回應', '疾管署', '特飯', '共餐', '需要', '攜手', '包商', '但是', '到', '清潔', '旅客', '「', '媒體', '各種', '大部分', '一同', '記者', '追問', '、', '確診', '整修', '飯店', '排除', '用餐', '新增', '在', '施工', '是否', '的', '中心', '都', '會', '餐飲部', '於', '樓層', '5', '疫情', '參加', '案', '任何', '透露', '可能', '持續', '流行', '人員', '工案', '？', '與', '和', '追查', '昨天', '。', '清', '有', '受訪', '周志浩', '時', '特飯店', '是', '被案', '今天', '不過', '；', '陳', '因此', '抗疫', '去過', '1120', '6', '可能性', '源', '或是', '中', '不', '3', '沒', '相關', '諾富', '店', '由', '地方', '水電', '員工', '水電工', '指揮', '長', '一館', '例外', '公', '）', '台大', '過諾富', '會前', '不明', '群聚', '是不是', '工作', '但還', '釐', '雙手', '曾到', '衛福部長', '佈', '醫院', '，', 'B1', '華航諾富', '接觸', '首', '」', '感染'}\n",
      "data:[(['華航諾富', '特飯', '群聚', '案'], '店'), (['特飯', '店', '案', '新增'], '群聚'), (['店', '群聚', '新增', '首'], '案'), (['群聚', '案', '首', '例外'], '新增'), (['案', '新增', '例外', '包商'], '首')]\n",
      "make_context_vector: tensor([111,   7,  99,  43])\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "text = \"華航諾富特飯店群聚案新增首例外包商水電工案1145確診，中央流行疫情指揮中心持續追查水電工感染源，衛福部長陳時中與疾管署長周志浩今天上午一同到台大醫院參加「清潔雙手，攜手抗疫」記者會，會前陳時中受訪透露，案1145可能曾到過諾富特飯店一館B1用餐，不排除任何感染可能。指揮中心昨天公佈的案1145，是在諾富特飯店的一館3、5、6樓層（整修樓層）工作，由於和飯店人員、旅客都沒有接觸，因此感染源不明；不過陳時中今天表示，在施工的地方大部分都是工作人員，但是可能有在B1的地方共餐。媒體追問，是否表示案1145有去過B1，是不是可能被案1120或是餐飲部的員工感染？陳時中回應，各種可能性都有，但還需要相關的釐清。\"\n",
    "# raw_text = [t for t in text]\n",
    "raw_text = list(jieba.cut(text))\n",
    "\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"vocab: {vocab}\")\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(f\"data:{data[:5]}\")\n",
    "\n",
    "#\n",
    "\n",
    "print(f\"make_context_vector: {make_context_vector(data[0][0], word_to_ix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e76255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "embedding_dim_num = 30\n",
    "device = torch.device('cuda:0')\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), embedding_dim=embedding_dim_num, context_size=CONTEXT_SIZE*2)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856ccf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([856.2447]), tensor([522.9579]), tensor([171.6826]), tensor([54.7270]), tensor([8.9709]), tensor([0.7604]), tensor([0.3382]), tensor([0.2860]), tensor([0.2510]), tensor([0.2251])]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in data:\n",
    "        context_ids = make_context_vector(context, word_to_ix)\n",
    "        context_ids = context_ids.to(device)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_ids)\n",
    "        label = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        label = label.to(device)\n",
    "        loss = loss_function(log_probs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889dde87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:['華航諾富'], vec: tensor([[ 0.0701,  0.5675,  1.7060, -0.5189,  0.3842, -0.9304, -0.4696, -0.2314,\n",
      "         -1.7867,  0.2036, -0.5264,  0.2282, -0.7893,  1.0054,  1.5950, -1.5383,\n",
      "          1.0659, -0.4129, -1.0124, -0.1491, -1.4219,  0.7584, -0.8240, -0.3780,\n",
      "          1.0067,  0.8340,  0.4849, -0.4860,  0.7368, -0.0794]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"text:{[data[0][0][0]]}, vec: {get_word_vec([data[0][0][0]],word_to_ix,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dd51879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5567]], device='cuda:0', grad_fn=<CdistBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_word_vec([data[0][0][0]],word_to_ix,device)\n",
    "b = get_word_vec([data[0][0][1]],word_to_ix,device)\n",
    "torch.cdist(a, b, p=embedding_dim_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d25eacd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "PATH_MODEL_SAVE = \"./save_word2vec.pt\"\n",
    "\n",
    "# Save:\n",
    "torch.save(model.state_dict(), PATH_MODEL_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a79020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6609,  0.0558, -0.8872,  0.3004,  0.1367,  0.8624,  1.3616, -0.6265,\n",
       "         -0.2723,  1.1247,  0.3074,  0.4339,  0.3673, -0.1834, -0.1669, -1.6277,\n",
       "         -0.6405,  1.4663, -1.0495, -1.2386, -0.5605,  0.8007,  0.0929,  0.0429,\n",
       "         -1.1079, -0.3637, -1.1880, -0.8322, -0.5966,  1.3929]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load:\n",
    "CONTEXT_SIZE = 2\n",
    "embedding_dim_num =30\n",
    "PATH_MODEL_SAVE = \"./save_word2vec.pt\"\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "model = CBOW(len(vocab), embedding_dim=embedding_dim_num, context_size=CONTEXT_SIZE*2)\n",
    "model.load_state_dict(torch.load(PATH_MODEL_SAVE))\n",
    "model.to(device)\n",
    "get_word_vec([\"華航諾富\"],word_to_ix,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54bb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
